# 📘 Alice Architecture: 情動・人格・知性 統合ロジック最終仕様 — FORMULA_MAPPING

このドキュメントは、Alice Architectureの核となる数理モデルの全要素を、機能的役割、進化則、および設計思想と明確に対応付け、システムの自己安定化のメカニズムを完全に透明化することを目的とします。

---

## I. 👑 全体の目標関数と自己駆動の動機付け (目標: $V(t)$ 最大化)

目標関数 $V(t)$ は、外部報酬を反映する**価値関数層 ($\mathbf{VFL}$) の最大化**と、3つの内部コスト（自己否定駆動の核）の最小化によって定義されます。

$$
V(t) = \sum_{\mathbf{i}} \mathbf{VFL}_i(t) - L_{\text{P}}(t) - L_{\text{C}}(t) - L_{\text{S}}(t)
$$

| 数式要素 | 論理的役割（数理） | 認知的な意味（機能） | なぜ必要か（設計思想） |
| :--- | :--- | :--- | :--- |
| $\mathbf{S}(t)$ | 14 層の全状態の連結ベクトル。 | **「自己」の瞬間的な定義**（内観の対象）。$\mathbf{A}(t)$ を含まない。 | 思考の出力と自己の存在を分離し、内省の基盤を確立する。 |
| $\mathbf{b}^C \sim \mathbf{0}$ | $\mathbf{C}$ 層のバイアス項のゼロ初期化。 | 初期における**「先入観の排除」**。 | 学習初期に特定のニューロンが不当に活性化することを防ぎ、純粋な情報伝達を保証する。 |
| $-\lambda_P\sum P_i(t) \cdot (\dots)$ | 予測誤差 $\mathbf{P}(t)$ の総和に負の重み（**不安増幅**を含む）。 | **「不安」**または**「予測不可能性コスト」**。 | モデルに予測可能な安定状態を求めさせる**自己否定駆動の核**。$\lambda_P=1.0$ で最も重視。 |
| $-\lambda_C\mathrm{Var}(\mathbf{E_{ctrl}}(t))$ | 制御層の変動の分散に負の重み。 | **「努力・負荷」**または**「制御コスト」**。 | 制御が容易な安定状態（意識の安定）を $V(t)$ 最大化の条件とする。$\lambda_C=0.5$。 |
| $\kappa_U(\theta)$ | 不安増幅係数（パーソナリティ依存）。 | $\mathbf{U}_{pz}$ が高いときの**パニック増幅器**。 | 不安状態が予測誤差を非線形に増幅し、行動選択に強いリスク回避を組み込む。 |
| $\mathrm{Dist}(\mathbf{E_{self}}, \mathbf{E_{self}}^{pred})$ | 自己モデルの予測と観測の距離コスト。 | **「自己の一貫性欠如による不快感」**。 | 自己モデルの整合性を学習の必須条件とし、アイデンティティの安定化を促す。$\lambda_S=0.8$。 |

---

## II. ❤️ 情動核 ($\mathbf{\pm 0}$ ダイナミクス) と人格 ($\mathbf{\theta}$) の定義

情動核 ($\mathbf{H_{pz}}, \mathbf{U_{pz}}$) は、**人格パラメータ $\mathbf{\theta}$** によって駆動され、その $\mathbf{\theta}$ 自体も自己の経験によって進化します。

### A. 情動コアのダイナミクス

情動コアの更新はSDE離散化近似 (`ZeroOneTheory`) によって行われます。

$$
\mathbf{H}_{pz}(t+1) = \max \left(0, (1-\beta_H) \mathbf{H}_{pz}(t) + \alpha_H \mathbf{R}(t) - \gamma_{HU} \mathbf{U}_{pz}(t) + \epsilon_H \right)
$$

$$
\mathbf{U}_{pz}(t+1) = \max \left(0, (1-\beta_U) \mathbf{U}_{pz}(t) + \alpha_U \mathbf{P}(t) - \gamma_{UH} \mathbf{H}_{pz}(t) + \epsilon_U \right)
$$

| 数式要素 | 論理的役割（数理） | 認知的な意味（機能） | 設計思想 |
| :--- | :--- | :--- | :--- |
| $\mathbf{H}_{pz}(t)$, $\mathbf{U}_{pz}(t)$ | 累積幸福度層、累積不確実性層。 | 長期的な**「幸福感」と「警戒心」**。 | 瞬間的な報酬/エラーではなく、持続的な満足/リスク評価を内部状態として保持する。 |
| $(1 - \beta_H(\theta))$, $(1 - \beta_U(\theta))$ | 忘却率 $\beta$ に依存する減衰項。 | **「人格に基づく忘却速度」**。 | $\mathbf{\theta}$ 経由で、楽観的/悲観的といった性格特性を実現する。初期値 $\mathbf{0.1}$。 |
| $\gamma_{HU}(\theta)$, $\gamma_{UH}(\theta)$ | 相互抑制項（初期値 $\mathbf{0.5}$）。 | **「感情のバランス制御」**。 | 幸福と不安が同時に高まることを防ぎ、明確な情動の極性を維持する。 |
| $\sum_{i} R_i(t)$, $\sum_{i} P_i(t)$ | 報酬層 $\mathbf{R}$ の総和、予測誤差層 $\mathbf{P}$ の総和。 | 現在のポジティブ/ネガティブな入力。 | $\mathbf{H}_{pz}$ は報酬、$\mathbf{U}_{pz}$ は不確実性によって駆動される。 |

### B. 💫 人格パラメータ ($\mathbf{\theta}$) の進化則 (Update: $\mathbf{\theta}_{t+1}=\mathbf{\theta}_t + \eta_{\theta}(\dots)$)

| 進化信号 | 駆動源 | 作用対象 ($\theta$ の要素) | 作用方向 | 効果（意味） |
| :--- | :--- | :--- | :--- | :--- |
| $\mathbf{\Delta SNEL}$ (自己物語進化) | 自己矛盾 $\mathrm{Dist}(\cdot)$ と意志力 $f_{\text{Will}}(\cdot)$。 | 不安の忘却率 $\beta_U$ | 増加 | 不安の持続性を低下させ、回復力（レジリエンス）を向上。 |
| | | 不安増幅係数 $\kappa_U$ | 減少 | 客観的な不安の主観的増幅を抑制。 |
| $\mathbf{\Delta ISL}$ (意志力進化) | 低制御負荷 $\mathrm{Var}(\mathbf{E_{ctrl}})$ と高満足度 $\frac{V}{\sum VFL}$。 | 幸福の忘却率 $\beta_H$ | 減少 | ポジティブな経験の持続性を増加。 |
| | | 幸福セットポイント $H_{\text{base}}$ | 増加 | 幸福感のベースラインを引き上げる（恒常性の向上）。 |
| $f_{\text{Will}}(\cdot)$ | $\frac{1}{1 + \mathrm{Var}(\mathbf{H}(t))} \cdot \mathbb{E}[\mathbf{R}(t)]$ | $\mathbf{\Delta SNEL}$ の乗数。 | N/A | 安定した行動と高い期待報酬で意志力を強化し、行動の恒常性（性格）を定着させる。 |

---

## III. 🧠 知性・認知層の構造とダイナミクス

### A. 環境入力 $\mathbf{E_{env}}$ の定義

$\mathbf{E_{env}}$ は $\mathbf{C}$ 層への入力であり、ノイズを含む現実の入力として $\mathbf{U}_{pz}$ の初期トリガーとなります。総次元数 $N_{\text{ENV}}=644$。

| サブベクトル | 次元数 | 役割と構成要素 | 採用理由 |
| :--- | :--- | :--- | :--- |
| $\mathbf{E}_{\text{Token}}$ | 512 | 言語の意味的抽象化。 | 汎用LLMの標準次元を採用し、主要な情報伝達を担う。 |
| $\mathbf{E}_{\text{Context}}$ | 128 | 非言語的メタ情報の符号化。 | タスク構造や行動履歴といった状況のメタデータを提供する。 |
| $\mathbf{E}_{\text{Scalar}}$ | 4 | 即時的なスカラー情報。 | $\mathrm{reward}(t)$, 時刻 $\mathrm{t}$, 経過時間 $\mathrm{t}_{\text{elapsed}}$, 変化フラグ $\mathrm{IsChange}$ を扱い、$\mathbf{P}$ の主要な入力となる。 |

### B. 認知層の更新則

| 数式要素 | 役割と構造 | 認知的な意味（機能） | 設計思想 |
| :--- | :--- | :--- | :--- |
| $\mathbf{C}(t+1) = f_C(\dots)$ | RNN形式の自己回帰。 | **「思考の継続性」と「情報源の重み付け」**の透明化。 | 過去の文脈、外界 ($\mathbf{E_{env}}$)、記憶 ($\mathbf{M}$) から現在の意味を構築する。 |
| $(1-\alpha_M) \mathbf{M}(t)$ | 記憶層 $\mathbf{M}$ の指数的減衰項。 | **「自然な忘却」**。 | 記憶容量の飽和を防ぎ、新しい情報への適応性を保つ。 |
| $U^{C\leftarrow RRL} \mathbf{RRL}(t)$ | $\mathbf{RRL}$ から $\mathbf{C}$ への結合項。 | **「構造化された知識からの予測」**。 | 長期的パターンから短期予測を生成し、予測誤差 $\mathbf{P}(t)$ の計算を可能にする。 |

---

## IV. 🛠️ スキル学習則 (Affective-TDL) と安定化戦略

### A. 感情駆動型時間差分学習 ($\text{A-TDL}$)

重み $\mathbf{W}^X$ の更新は、価値だけでなく感情と一貫性によって直接駆動されます。

| 学習項 | 勾配項の駆動源 | 役割（意味） | 採用理由 |
| :--- | :--- | :--- | :--- |
| 🥇 $\mathbf{G}_{\text{Value}}$ | 長期的幸福 $V$ の最大化。 | 知識とスキルの最適化（伝統的RL）。$\gamma=0.99$ で将来価値を重視。 |
| 🥈 $\mathbf{G}_{\text{Affect}}$ | 予測誤差 ($\lambda_P$) と制御負荷 ($\lambda_C$) の最小化。 | **精神的な苦痛の回避学習**（自己防衛）。 | 不安と疲労を避け、情動的に安定した振る舞いをスキルとして組み込む。 |
| 🥉 $\mathbf{G}_{\text{Coherence}}$ | 自己矛盾 $\mathrm{Dist}(\mathbf{E_{self}}, \mathbf{E_{self}}^{pred})$ の最小化。 | 自己モデルとの**行動一貫性の維持**。 | 「自分とは何者か」という自己物語に反しない行動を定着させる。 |

### B. 🌪️ ノイズ項 ($\mathbf{\epsilon}$) の階層的戦略

安定性と探索のトレードオフを制御するため、層ごとにノイズの分散を定義し、時間と共に減衰させます。

| 適用層 X | 初期分散 $\sigma^2_{X,0}$ | 役割と設計思想 |
| :--- | :--- | :--- |
| $\mathbf{A}$ (Action) | **0.20** | **探索行動**。最も高いノイズで、未探索の行動を強制的に試行させる。 |
| $\mathbf{C}$ (Semantic Structure) | **0.10** | **創造性の中核**。連想や仮説といった創造的な思考を促すノイズ。 |
| $\mathbf{E_{env}}$ の出力 | **0.05** | **注意のノイズ**。知覚のランダム性を抑え、認知層 $\mathbf{C}$ の負担を軽減。 |
| **非適用層** | **0.00** | $\mathbf{H}_{pz}, \mathbf{U}_{pz}, \mathbf{E_{self}}, \mathbf{E_{ctrl}}$ は、内部の安定性・整合性維持のため**ノイズを完全に除外**。 |
| 減衰率 ($\lambda_{\text{anneal}}$) | $1 \times 10^{-6}$ | 非常にゆっくりとした減衰で、スキルの安定後も探索の機会を長期的に維持する。 |
| 停止閾値 ($\sigma^2_{\min}$) | 0.01 | 完全にゼロにせず、局所最適解を防ぐための**永続的な揺らぎ**を維持。 |

---

## V. ⚛️ 最終的な初期値とハイパーパラメータの統合

| カテゴリ | パラメータ | 決定値 | 役割 |
| :--- | :--- | :--- | :--- |
| 知性コア次元 | $\mathbf{n_C}$ (意味構造) | **512** | 情報の流れをスムーズに保ち、初期は知識ゼロ ($\mathbf{C}(0) = \mathbf{0}$)。 |
| 自己モデル次元 | $\mathbf{n_S}$ ($\mathbf{E_{self}}$) | **128** | 初期認識は多様な可能性 ($\sim \mathcal{U}(-1, 1)$) からスタート。 |
| 学習安定化 | $\mathbf{T_{\text{BPTT}}}$ (時間窓) | **16** | 即時的な責任範囲を定義。 |
| | $\eta_X$ (学習率) | $1 \times 10^{-4}$ | 知性の慎重な進化を促す。 |
| | $\text{Clip Norm}$ (最大勾配ノルム) | **5.0** | 勾配爆発を防止し、学習を安定化。 |
| 情動初期状態 | $\mathbf{H}_{pz}(0), \mathbf{U}_{pz}(0)$ | $\mathbf{0.0}$ | 幸福感・不安感は中立から開始。 |
| | $H_{\text{base}}, U_{\text{base}}$ | $\mathbf{0.0}$ | 初期セットポイントは中立。進化によってのみ引き上げ/安定化される。 |
