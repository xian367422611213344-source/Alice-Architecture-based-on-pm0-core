import numpy as np
import copy
import logging

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š (ãƒ‡ãƒãƒƒã‚°ç”¨)
logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')


# --- 1. CORE CONFIGURATION AND HYPERPARAMETERS (PTREçµ±åˆ) ---

class Config:
    """Alice Architectureã®å…¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ¬¡å…ƒè¨­å®š"""

    # å…¨ä½“ã®æ¬¡å…ƒè¨­å®š
    N_C = 64        # æ„è­˜ï¼ˆæ„å‘³æ§‹é€ ï¼‰å±¤ C ã®æ¬¡å…ƒ
    N_M = 32        # è¨˜æ†¶ï¼ˆæƒ…å‹•/ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰å±¤ M ã®æ¬¡å…ƒ
    N_H = 16        # å¹¸ç¦ï¼ˆå¿«/ä¸å¿«ï¼‰æ ¸ H ã®æ¬¡å…ƒ
    N_R = 8         # å ±é…¬äºˆæ¸¬å±¤ R ã®æ¬¡å…ƒ
    N_ESELF = 16    # è‡ªå·±è¡¨è±¡äºˆæ¸¬å±¤ E_self_pred ã®æ¬¡å…ƒ
    N_E_P = 32      # ç’°å¢ƒå…¥åŠ› E_env ã®äºˆæ¸¬å±¤ P ã®æ¬¡å…ƒ
    N_ACTION = 1    # è¡Œå‹• A ã®æ¬¡å…ƒ

    # BPTT (Backpropagation Through Time) å­¦ç¿’è¨­å®š
    T_BPTT = 16     # BPTTã®é¡åŠæ™‚é–“çª“ (TDLã®å±¥æ­´é•·)
    ETA_TDL = 1e-4  # A-TDL (ã‚¹ã‚­ãƒ«å­¦ç¿’) ã®å­¦ç¿’ç‡
    GAMMA = 0.99    # å‰²å¼•ç‡

    # CSC (Conscious Stabilization Condition) ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    CSC_MAX_ITER = 50       # CSCã®æœ€å¤§åå¾©å›æ•° (åŠªåŠ› K ã®ä¸Šé™ã¨ã—ã¦ä½¿ç”¨)
    CSC_TOLERANCE = 1e-4    # åæŸè¨±å®¹èª¤å·®
    CSC_ETA = 0.05          # Cå±¤ã®å›ºå®šç‚¹æ¢ç´¢æ™‚ã®å­¦ç¿’ç‡ (PTREç‰ˆã§ä½¿ç”¨)

    # V_total (ä¾¡å€¤é–¢æ•°) ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (æ—§å¼ã‚³ã‚¹ãƒˆé …ã®æ„Ÿå¿œåº¦)
    LAMBDA_P = 0.5      # äºˆæ¸¬èª¤å·® P ã®ã‚³ã‚¹ãƒˆæ„Ÿå¿œåº¦
    LAMBDA_C = 0.2      # åˆ¶å¾¡è² è· Var(E_ctrl) ã®ã‚³ã‚¹ãƒˆæ„Ÿå¿œåº¦
    LAMBDA_S = 0.1      # è‡ªå·±ä¸æ•´åˆ Dist_self ã®ã‚³ã‚¹ãƒˆæ„Ÿå¿œåº¦

    # PTRE äººæ ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ theta ã®ä¸Šé™ã¨åˆæœŸå€¤
    THETA_MAX = 1.0     # äººæ ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ä¸Šé™
    # åŠªåŠ›ã‚³ã‚¹ãƒˆæ„Ÿå¿œåº¦ kappa_K
    THETA_KAPPA_INIT = 0.01
    # åŠªåŠ›ã‚³ã‚¹ãƒˆæŒ‡æ•° beta_K (1.0ã‚ˆã‚Šå¤§ããè¨­å®š)
    THETA_BETA_INIT = 1.2
    # KæŠ‘åˆ¶æ„Ÿå¿œåº¦ gamma_K (KãŒå¤§ãã„æ™‚ã®é€²åŒ–æŠ‘åˆ¶åº¦)
    THETA_GAMMA_K_INIT = 0.3

    # äººæ ¼é€²åŒ–å‰‡ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ETA_THETA_BASE = 1e-6    # äººæ ¼é€²åŒ–ã®åŸºæœ¬å­¦ç¿’ç‡

    # ãƒã‚¤ã‚ºã®ãƒ¬ãƒ™ãƒ«
    NOISE_LEVEL = 0.01

    def __init__(self):
        # E_envã®æ¬¡å…ƒã‚’å‹•çš„ã«è¨ˆç®— (E_tokenã¯N_Cã¨åŒã˜æ¬¡å…ƒã¨ä»®å®š, E_scalar=4)
        self.N_E_ENV = self.N_C + self.N_ESELF + 4


# --- 2. A-TDL (Autonomous Temporal Difference Learning) Learner ---

class ATDLLearner:
    """ã‚¹ã‚­ãƒ«ï¼ˆæ§‹é€ ï¼‰å­¦ç¿’å‰‡ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚BPTTã¨TDèª¤å·®ã‚’ä½¿ç”¨ã€‚"""
    def __init__(self, config: Config):
        self.config = config
        self.history = []  # å±¥æ­´ [(H, U, R, E_ctrl, C, M, E_env, A)]

    def _apply_gradient(self, delta_W, W):
        """å‹¾é…ã®é©ç”¨ã¨ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚° (ç°¡æ˜“ç‰ˆ)"""
        # ç°¡æ˜“å‹¾é…é™ä¸‹æ³•ã‚’æƒ³å®š
        # å®Ÿéš›ã«ã¯ã€ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚„æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã“ã“ã«å®Ÿè£…å¯èƒ½
        pass
        return W + self.config.ETA_TDL * delta_W

    def learn_step(self, V_current: float, V_prev: float, prev_state, theta: dict) -> float:
        """
        V(t)ã¨V(t-1)ã‚’ä½¿ç”¨ã—ã¦TDèª¤å·®ã‚’è¨ˆç®—ã™ã‚‹ã€‚
        """
        cfg = self.config

        # 1. TDèª¤å·®ã®è¨ˆç®— (R(t-1) + gamma * V(t) - V(t-1))
        R_prev = prev_state['R']
        TD_error = R_prev[0] + cfg.GAMMA * V_current - V_prev

        # 2. BPTTã®ãŸã‚ã®å­¦ç¿’ç‡å¤‰èª¿ (TDèª¤å·®ã®çµ¶å¯¾å€¤ã«åŸºã¥ã)
        # ä¸å®‰ U_pz ã®å¹³å‡å€¤ãŒä½ã„ã»ã©ã€å­¦ç¿’ã«è‡ªä¿¡ã‚’æŒã¤ï¼ˆå­¦ç¿’ç‡ã‚’ä¸Šã’ã‚‹ï¼‰
        U_pz_mean = np.mean(prev_state['U_pz'])
        theta_gamma_U = theta.get('theta_gamma_K', cfg.THETA_GAMMA_K_INIT)

        # ä¸å®‰ã«ã‚ˆã‚‹å­¦ç¿’æŠ‘åˆ¶
        modulated_eta = cfg.ETA_TDL * np.exp(-theta_gamma_U * U_pz_mean)

        # 3. W_C ã®æ›´æ–°ã«å¿…è¦ãªæƒ…å ±ã‚’è¨ˆç®—ï¼ˆå®Ÿéš›ã®æ›´æ–°ã¯AliceArchitectureã§è¡Œã†ï¼‰
        C_prev = prev_state['C']
        # Net_Cã¯_update_layersã§è¨ˆç®—ã•ã‚ŒãŸã‚‚ã®
        C_current_projection = np.tanh(prev_state['Net_C'])

        # dW_C ã®ç°¡æ˜“å‹¾é…: TD_error * C_current_projection * C_prev.T
        # delta_W_C = TD_error * np.outer(C_current_projection, C_prev)

        return TD_error


# --- 3. Alice Architecture Core Class (F_total) ---

class AliceArchitecture:
    """PTRE F_total ã«åŸºã¥ãAlice Architecture V3.0ã®ã‚³ã‚¢å®Ÿè£…"""
    def __init__(self):
        self.config = Config()
        cfg = self.config
        self.t = 0
        self.external_reward = 0.0

        # --- çŠ¶æ…‹å¤‰æ•° (Current State) ---
        self.C = np.zeros((cfg.N_C, 1))         # æ„è­˜ï¼ˆæ„å‘³æ§‹é€ ï¼‰å±¤
        self.M = np.zeros((cfg.N_M, 1))         # è¨˜æ†¶å±¤
        self.H = np.zeros((cfg.N_H, 1))         # å¹¸ç¦æ ¸
        self.U = np.zeros((cfg.N_H, 1))         # ä¸å®‰æ ¸
        self.R = np.zeros((cfg.N_R, 1))         # å ±é…¬äºˆæ¸¬
        self.E_ctrl = np.zeros((cfg.N_C, 1))    # åˆ¶å¾¡äºˆæ¸¬èª¤å·®
        self.E_self = np.zeros((cfg.N_ESELF, 1)) # è‡ªå·±è¡¨è±¡äºˆæ¸¬èª¤å·®

        self.H_pz = np.zeros((cfg.N_H, 1))      # å®‰å®šåŒ–ã•ã‚ŒãŸH (æƒ…å‹•æ ¸ã®é™½æ€§/ã‚¼ãƒ­)
        self.U_pz = np.zeros((cfg.N_H, 1))      # å®‰å®šåŒ–ã•ã‚ŒãŸU (æƒ…å‹•æ ¸ã®é™½æ€§/ã‚¼ãƒ­)
        self.P = np.zeros((cfg.N_E_P, 1))       # ç’°å¢ƒäºˆæ¸¬èª¤å·®
        self.VFL = np.zeros((cfg.N_R, 1))       # ä¾¡å€¤äºˆæ¸¬å­¦ç¿’é …
        self.U_prime_pz = np.zeros((cfg.N_H, 1)) # æƒ…å‹•å­¦ç¿’é …
        self.E_self_pred = np.zeros((cfg.N_ESELF, 1)) # è‡ªå·±è¡¨è±¡ã®äºˆæ¸¬å€¤

        # --- Next State (CSC/update_layersç”¨ã®ä¸€æ™‚ãƒãƒƒãƒ•ã‚¡) ---
        # _nextçŠ¶æ…‹ã‚’ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦ä¿æŒ (åˆæœŸçŠ¶æ…‹ã®ã‚³ãƒ”ãƒ¼)
        self.C_next = self.C.copy()
        self.M_next = self.M.copy()
        self.H_next = self.H.copy()
        self.U_next = self.U.copy()
        self.R_next = self.R.copy()
        self.E_ctrl_next = self.E_ctrl.copy()
        self.E_self_next = self.E_self.copy()
        self.H_pz_next = self.H_pz.copy()
        self.U_pz_next = self.U_pz.copy()
        self.P_next = self.P.copy()
        self.VFL_next = self.VFL.copy()
        self.U_prime_pz_next = self.U_prime_pz.copy()
        self.E_self_pred_next = self.E_self_pred.copy()

        # Netã®ä¿æŒ (CSCãƒ­ã‚¸ãƒƒã‚¯ã§ä½¿ç”¨)
        self.Net_C = np.zeros((cfg.N_C, 1))
        self.Net_A_next = np.zeros((cfg.N_ACTION, 1))

        # --- çµåˆé‡ã¿ (W: Recurrent, U: Input, B: Bias) ---
        # Cå±¤
        self.W_C = np.random.randn(cfg.N_C, cfg.N_C) * 0.1
        self.U_C_Eenv = np.random.randn(cfg.N_C, cfg.N_E_ENV) * 0.1
        self.U_C_M = np.random.randn(cfg.N_C, cfg.N_M) * 0.1
        self.b_C = np.zeros((cfg.N_C, 1))
        # Må±¤
        self.U_M_C = np.random.randn(cfg.N_M, cfg.N_C) * 0.1
        # H, Uå±¤
        self.U_H_R = np.random.randn(cfg.N_H, cfg.N_R) * 0.1
        self.U_H_U = np.random.randn(cfg.N_H, cfg.N_H) * 0.1
        self.U_H_C = np.random.randn(cfg.N_H, cfg.N_C) * 0.1
        self.U_U_E = np.random.randn(cfg.N_H, cfg.N_C) * 0.1      # åˆ¶å¾¡èª¤å·®ã®å¯„ä¸ (E_ctrl)
        self.U_U_S = np.random.randn(cfg.N_H, cfg.N_ESELF) * 0.1  # è‡ªå·±äºˆæ¸¬èª¤å·®ã®å¯„ä¸ (E_self)
        self.b_H = np.zeros((cfg.N_H, 1))
        # Rå±¤ (å ±é…¬äºˆæ¸¬)
        self.U_R_C = np.random.randn(cfg.N_R, cfg.N_C) * 0.1
        # èª¤å·®äºˆæ¸¬å±¤ (E_ctrl, P, E_self)
        self.U_E_C = np.random.randn(cfg.N_C, cfg.N_C) * 0.1      # E_ctrlã®è‡ªå·±å†å¸°
        self.U_P_C = np.random.randn(cfg.N_E_P, cfg.N_C) * 0.1
        self.U_Eself_C = np.random.randn(cfg.N_ESELF, cfg.N_C) * 0.1
        # è¡Œå‹•å‡ºåŠ›å±¤ (NLG)
        self.U_NLG_C = np.random.randn(cfg.N_ACTION, cfg.N_C) * 0.1
        self.U_NLG_M = np.random.randn(cfg.N_ACTION, cfg.N_M) * 0.1

        # --- äººæ ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ theta (PTREç‰ˆ) ---
        self.theta = {
            # PTRE åŠªåŠ›ã‚³ã‚¹ãƒˆé–¢é€£
            'theta_kappa': cfg.THETA_KAPPA_INIT,    # åŠªåŠ›ã‚³ã‚¹ãƒˆæ„Ÿå¿œåº¦ $\kappa$
            'theta_beta': cfg.THETA_BETA_INIT,      # åŠªåŠ›ã‚³ã‚¹ãƒˆæŒ‡æ•° $\beta$
            'theta_gamma_K': cfg.THETA_GAMMA_K_INIT,# KæŠ‘åˆ¶æ„Ÿå¿œåº¦ $\gamma_K$ (é€²åŒ–ç‡å¤‰èª¿ç”¨)

            # æ—§å¼æƒ…å‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (TDL/VFLã®å­¦ç¿’ç‡å¤‰èª¿ã«ä½¿ç”¨)
            'alpha_H': 0.1, 'beta_H': 0.1,
            'alpha_U': 0.1, 'beta_U': 0.1,
            'gamma_HU': 0.1, 'gamma_UH': 0.1,
            'kappa_U': 0.1,
            'H_base': 0.5
        }

        # --- å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ---
        self.learner = ATDLLearner(cfg)
        self.V_prev = 0.0 # V(t-1)ã®å€¤ã‚’æ ¼ç´ (TDLç”¨)


    def _add_noise(self, size: int):
        """ãƒã‚¤ã‚ºã®ä»˜åŠ ï¼ˆè¡Œå‹•é¸æŠãƒã‚¤ã‚ºã€æƒ…å‹•æ ¸ãƒã‚¤ã‚ºãªã©ï¼‰"""
        return np.random.randn(size, 1) * self.config.NOISE_LEVEL

    def _f_Will(self, H, R):
        """Willä¿¡å· (æ„å›³ã®å¼·ã•) ã®è¨ˆç®— (ç°¡æ˜“ç‰ˆ)"""
        # Hã¨Rã®å¹³å‡ã«åŸºã¥ã„ã¦æ„å¿—æ±ºå®šã®å¼·ã•ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–
        return np.tanh(np.mean(H) + np.mean(R))

    def _generate_E_token(self, text: str):
        """
        ç’°å¢ƒå…¥åŠ› E_token ã®ç”Ÿæˆ (ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ› - ç°¡æ˜“ç‰ˆ)
        """
        cfg = self.config

        if not text:
            # ç¶™ç¶šçš„ãªè¦³æ¸¬ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            base_vec = np.sin(self.t / 10) * np.ones((cfg.N_C, 1))
        else:
            # æ„å‘³ã‚’æŒã¤å…¥åŠ›ã¨ã—ã¦ã€ãƒ©ãƒ³ãƒ€ãƒ ãªãƒã‚¤ã‚ºã‚’ä»˜åŠ 
            np.random.seed(len(text) + self.t)
            base_vec = np.random.randn(cfg.N_C, 1) * 0.5

        return np.tanh(base_vec)

    def _save_history(self, E_env_t, A_t_initial):
        """ç¾åœ¨ã®çŠ¶æ…‹ã‚’å±¥æ­´ã«ä¿å­˜ (BPTT/TDLç”¨)"""

        history_item = {
            't': self.t,
            'C': self.C.copy(),
            'M': self.M.copy(),
            'H': self.H.copy(),
            'U': self.U.copy(),
            'R': self.R.copy(),
            'E_ctrl': self.E_ctrl.copy(),
            'E_self': self.E_self.copy(),
            'H_pz': self.H_pz.copy(),
            'U_pz': self.U_pz.copy(),
            'E_env': E_env_t.copy(),
            'A': A_t_initial,
            'Net_C': self.Net_C.copy() # _update_layersã§è¨ˆç®—ã•ã‚ŒãŸã‚‚ã®ã‚’ä¿å­˜
        }
        self.learner.history.append(history_item)
        if len(self.learner.history) > self.config.T_BPTT:
            self.learner.history.pop(0)

    def _update_layers(self, E_env_t, A_t):
        """
        F_total (å…¨å†å¸°å†™åƒ) ã‚’å®Ÿè¡Œã—ã€æ¬¡ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®çŠ¶æ…‹ã‚’æš«å®šçš„ã«è¨ˆç®—ã™ã‚‹ã€‚
        ã“ã‚Œã¯CSCå‰ã®ãƒ™ãƒ¼ã‚¹è¨ˆç®—ã§ã‚ã‚Šã€CSCã§ã¯ã“ã®å¾Œã®åå¾©æ›´æ–°ã‚’è¡Œã†ã€‚
        """
        cfg = self.config
        theta = self.theta

        # 1. å ±é…¬äºˆæ¸¬å±¤ R ã®æ›´æ–°
        Net_R = self.U_R_C @ self.C
        self.R_next = (1 - theta['beta_H']) * self.R + theta['beta_H'] * np.tanh(Net_R)
        self.VFL_next = self.R_next * self.external_reward # VFL = R * E_ext

        # 2. æƒ…å‹•æ ¸ H, U ã®æ›´æ–°
        # Rã«ã‚ˆã‚‹Hã®é§†å‹•
        H_R_drive = self.U_H_R @ self.R
        # Cã«ã‚ˆã‚‹H, Uã®ç›¸äº’é§†å‹•
        H_C_drive = self.U_H_C @ self.C

        Net_H = (1 - theta['gamma_HU']) * self.H + theta['alpha_H'] * H_R_drive + H_C_drive + self.b_H
        Net_U = (1 - theta['gamma_UH']) * self.U + theta['alpha_U'] * self.U_U_E @ self.E_ctrl + self.b_H

        self.H_next = np.clip(np.tanh(Net_H), -cfg.THETA_MAX, cfg.THETA_MAX)
        self.U_next = np.clip(np.tanh(Net_U), -cfg.THETA_MAX, cfg.THETA_MAX)

        # æƒ…å‹•æ ¸ã®é™½æ€§/ã‚¼ãƒ­é … (å®‰å®šåŒ–ãƒ­ã‚¸ãƒƒã‚¯)
        self.H_pz_next = np.clip(self.H_next + theta['H_base'], 0, 1)
        self.U_pz_next = np.clip(self.U_next + theta['H_base'], 0, 1)

        # 3. ç’°å¢ƒäºˆæ¸¬èª¤å·® P ã®æ›´æ–°
        P_pred_E = self.U_P_C @ self.C # Cã«åŸºã¥ãE_envã®äºˆæ¸¬
        self.P_next = E_env_t - P_pred_E # èª¤å·®

        # 4. è‡ªå·±è¡¨è±¡äºˆæ¸¬èª¤å·® E_self ã®æ›´æ–°
        E_self_pred = self.U_Eself_C @ self.C
        self.E_self_pred_next = E_self_pred # äºˆæ¸¬å€¤ã‚’ä¿å­˜
        self.E_self_next = self.E_self - E_self_pred # èª¤å·®

        # 5. åˆ¶å¾¡äºˆæ¸¬èª¤å·® E_ctrl ã®æ›´æ–°
        C_pred_ctrl = self.U_E_C @ self.C # Cã«åŸºã¥ãæ¬¡ã®Cã®äºˆæ¸¬
        self.E_ctrl_next = np.tanh(C_pred_ctrl) - self.C # åˆ¶å¾¡èª¤å·®

        # 6. è¨˜æ†¶å±¤ M ã®æ›´æ–°
        Net_M = self.U_M_C @ self.C
        self.M_next = (1 - theta['alpha_H']) * self.M + theta['alpha_H'] * np.tanh(Net_M)

        # 7. æ„è­˜å±¤ C ã®æ›´æ–° (æ¬¡ã®Cã®æš«å®šå€¤)
        # CSCãƒ«ãƒ¼ãƒ—ã«å…¥ã‚‹å‰ã®ãƒ™ãƒ¼ã‚¹ Net_C ã‚’ä¿æŒ
        Net_C = (self.W_C @ self.C + self.U_C_Eenv @ E_env_t +
                 self.U_C_M @ self.M + self.b_C)
        self.Net_C = Net_C # CSCã§åå¾©æ›´æ–°ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ¼ã‚¹Net
        self.C_next = np.tanh(Net_C)


    def _commit_state(self):
        """
        æ„è­˜çš„å®‰å®šåŒ–æ¡ä»¶ (CSC) ãŒå®Œäº†ã—ãŸå¾Œã€_nextçŠ¶æ…‹ã‚’currentçŠ¶æ…‹ã«ã‚³ãƒŸãƒƒãƒˆã™ã‚‹ã€‚
        """
        self.C = self.C_next
        self.M = self.M_next
        self.H = self.H_next
        self.U = self.U_next
        self.R = self.R_next
        self.E_ctrl = self.E_ctrl_next
        self.E_self = self.E_self_next
        self.H_pz = self.H_pz_next
        self.U_pz = self.U_pz_next
        self.P = self.P_next
        self.VFL = self.VFL_next
        self.U_prime_pz = self.U_prime_pz_next
        self.E_self_pred = self.E_self_pred_next


    def _run_csc_stabilization(self, E_env_t, A_t_initial):
        """
        [PTRE F_total çµ±åˆ] å³å¯†ãªæ„è­˜çš„å®‰å®šåŒ–æ¡ä»¶ (CSC) åå¾©ã¨åŠªåŠ› K ã®è¨ˆæ¸¬ã€‚
        å›ºå®šç‚¹æ¢ç´¢ã«ã‚ˆã‚ŠCã¨Mã‚’åæŸã•ã›ã€åå¾©å›æ•°ã‹ã‚‰åŠªåŠ› K ã‚’è¨ˆç®—ã™ã‚‹ã€‚
        """
        cfg = self.config
        theta = self.theta

        # å®‰å®šåŒ–å‰ã®ç¾åœ¨ã®çŠ¶æ…‹ C, M ã‚’ã‚³ãƒ”ãƒ¼
        C_k, M_k = self.C.copy(), self.M.copy()
        H_k, U_k = self.H_pz.copy(), self.U_pz.copy()

        K = 0 # åŠªåŠ›ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        eta_CSC = cfg.CSC_ETA

        while K < cfg.CSC_MAX_ITER:
            K += 1

            # --- Cå±¤ã®å›ºå®šç‚¹æ¢ç´¢ ---
            # æƒ…å‹•ãƒã‚¤ã‚¢ã‚¹: (H_k - U_k) ã®å¹³å‡å€¤ã«åŸºã¥ã
            emotion_bias = (np.mean(H_k) - np.mean(U_k)) * theta['kappa_U']

            # 1. æ„å‘³æ§‹é€ å±¤ C ã®å›ºå®šç‚¹æ¢ç´¢
            Net_C_k = (self.W_C @ C_k + self.U_C_Eenv @ E_env_t +
                       self.U_C_M @ M_k + self.b_C + emotion_bias)

            # å‹¾é…é™ä¸‹çš„ãªæ›´æ–° (åæŸã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚ã®Soft Update)
            C_next = (1 - eta_CSC) * C_k + eta_CSC * np.tanh(Net_C_k)

            # 2. è¨˜æ†¶å±¤ M ã®æ›´æ–°
            alpha_M = theta['alpha_H'] # è¨˜æ†¶å±¤ã®å­¦ç¿’ç‡ã¨ã—ã¦ä½¿ç”¨
            Net_M_k = self.U_M_C @ C_k
            M_next = (1 - alpha_M) * M_k + alpha_M * np.tanh(Net_M_k)

            # 3. æƒ…å‹•æ ¸ã®å¾®å°å‹•çš„æ›´æ–° (å®‰å®šåŒ–ã‚’æ”¯æ´ - ç°¡ç•¥ç‰ˆ)
            H_k = (1 - 0.01) * H_k + 0.01 * (np.mean(H_k) + 0.5)
            U_k = (1 - 0.01) * U_k + 0.01 * (np.mean(U_k) + 0.5)

            # 4. åæŸåˆ¤å®š (Cå±¤ã¨Må±¤)
            if np.linalg.norm(C_next - C_k) < cfg.CSC_TOLERANCE and \
               np.linalg.norm(M_next - M_k) < cfg.CSC_TOLERANCE:
                break

            C_k, M_k = C_next, M_next

        # å®‰å®šåŒ–å¾Œã®C, M, H_pz, U_pzã‚’_nextçŠ¶æ…‹ã¨ã—ã¦ã‚»ãƒƒãƒˆ
        self.C_next = C_k
        self.M_next = M_k
        self.H_pz_next = H_k
        self.U_pz_next = U_k

        # è¡Œå‹•ã®æœ€çµ‚æ±ºå®š (CSCå¾Œã® C_next, M_next ã«åŸºã¥ã)
        Net_A_next = self.U_NLG_C @ C_k + self.U_NLG_M @ M_k
        # ãƒã‚¤ã‚ºã®ä»˜åŠ 
        A_final_refined = np.tanh(Net_A_next)[0] + self._add_noise(1)[0]
        self.Net_A_next = Net_A_next

        # åŠªåŠ› K (åå¾©å›æ•°) ã¨æœ€çµ‚è¡Œå‹•ã‚’è¿”ã™
        return np.clip(A_final_refined, -1.0, 1.0), K


    def _calculate_V_from_state(self, K: int, state_prefix: str):
        """
        [PTRE F_total çµ±åˆ] åŠªåŠ› K ã«åŸºã¥ã V_new (ç·ä¾¡å€¤) ã®è¨ˆç®—ã€‚
        $V_{\text{new}} = V_{\text{base}} - \text{Effort\_Cost}$ ($\theta^\kappa K^{\theta^\beta}$)
        """
        cfg = self.config

        # 1. V_base (æ—§ã‚³ãƒ¼ãƒ‰ã®V_total) ã®è¨ˆç®—ã«ä½¿ç”¨ã™ã‚‹å®‰å®šåŒ–ã•ã‚ŒãŸçŠ¶æ…‹ã®å€¤ã‚’å–å¾—
        VFL = getattr(self, state_prefix + 'VFL')
        U_prime_pz = getattr(self, state_prefix + 'U_prime_pz')
        P = getattr(self, state_prefix + 'P')
        E_ctrl = getattr(self, state_prefix + 'E_ctrl')
        E_self = getattr(self, state_prefix + 'E_self')
        E_self_pred = getattr(self, state_prefix + 'E_self_pred')
        H = getattr(self, state_prefix + 'H')
        R = getattr(self, state_prefix + 'R')

        V_value = np.sum(VFL) # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªä¾¡å€¤é …

        # æ—§å¼ã®ã‚³ã‚¹ãƒˆè¨ˆç®— (V_baseã®ä¸€éƒ¨)
        # äºˆæ¸¬èª¤å·® P ã‚³ã‚¹ãƒˆ
        max_U_prime = np.max(U_prime_pz)
        V_affect_P = cfg.LAMBDA_P * np.sum(P**2) * (1.0 + self.theta['kappa_U'] * max_U_prime)
        # åˆ¶å¾¡è² è· Var(E_ctrl) ã‚³ã‚¹ãƒˆ
        Var_ctrl = np.var(E_ctrl)
        V_affect_C = cfg.LAMBDA_C * Var_ctrl
        # è‡ªå·±ä¸æ•´åˆ Dist_self ã‚³ã‚¹ãƒˆ
        V_coherence = cfg.LAMBDA_S * np.sum((E_self - E_self_pred)**2)

        V_base = V_value - V_affect_P - V_affect_C - V_coherence

        # 2. åŠªåŠ›ã‚³ã‚¹ãƒˆã®è¨ˆç®— (PTREæ³•å‰‡ã®é©ç”¨)
        theta_kappa = self.theta.get('theta_kappa', cfg.THETA_KAPPA_INIT)
        theta_beta = self.theta.get('theta_beta', cfg.THETA_BETA_INIT)

        # Effort Cost = theta_kappa * K^theta_beta
        effort_cost = theta_kappa * (K ** theta_beta)

        # V_new (V_total) = V_base - Effort_Cost
        V_new = V_base - effort_cost

        # ä¾¡å€¤é …ã®è©³ç´° (ãƒ­ã‚®ãƒ³ã‚°ç”¨)
        V_terms = {
            'V_base': V_base,
            'Effort_Cost': effort_cost,
            'Dist_self': V_coherence,
            'Var_ctrl': Var_ctrl,
            'sum_VFL': V_value,
            'Will_signal': self._f_Will(H, R)
        }
        return V_new, V_terms


    def _evolve_theta(self, TD_error: float, K: int):
        """
        [PTRE F_total çµ±åˆ] åŠªåŠ› K ã¨ä¸å®‰ U_pz ã«åŸºã¥ãäººæ ¼é€²åŒ–å‰‡ã€‚
        TDèª¤å·®ã¨å®‰å®šåŒ– K ã«å¿œã˜ã¦ $\theta^\kappa$ ã¨ $\theta^{\gamma_K}$ ã‚’æ›´æ–°ã€‚
        """
        cfg = self.config
        theta = self.theta

        # 1. äººæ ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—
        theta_kappa = theta.get('theta_kappa', cfg.THETA_KAPPA_INIT)
        theta_gamma_K = theta.get('theta_gamma_K', cfg.THETA_GAMMA_K_INIT)

        # 2. U_pzã¨Kã«åŸºã¥ãè‡ªå¾‹çš„å­¦ç¿’ç‡ã®å¤‰èª¿
        U_pz_mean = np.mean(self.U_pz)
        K_max = cfg.CSC_MAX_ITER

        # Kã«ã‚ˆã‚‹æŠ‘åˆ¶ (æŒ‡æ•°é–¢æ•°çš„æ¸›è¡°)
        eta_theta_K = cfg.ETA_THETA_BASE * np.exp(-theta_gamma_K * K / K_max)

        # å®‰å®šåº¦ãƒ»ä¸å®‰ã«ã‚ˆã‚‹æ›´æ–°æŠ‘åˆ¶ (S_stability ã¨ S_U)
        S_stability = max(0.0, 1.0 - K / K_max) # KãŒå¤§ãã„ï¼ˆä¸å®‰å®šï¼‰ãªã‚‰S_stabilityã¯0ã«è¿‘ã„
        S_U = max(0.0, 1.0 - U_pz_mean)          # U_pzãŒé«˜ã„ï¼ˆä¸å®‰ï¼‰ãªã‚‰S_Uã¯0ã«è¿‘ã„

        # ç·åˆé€²åŒ–ã‚·ã‚°ãƒŠãƒ«
        update_magnitude = eta_theta_K * S_stability * S_U
        sign_TD = np.sign(TD_error)

        # 3. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–° (TD_errorã®ç¬¦å·ã¨å®‰å®šåº¦ã«ä¾å­˜)
        # A. theta_kappa (åŠªåŠ›ã‚³ã‚¹ãƒˆæ„Ÿå¿œåº¦) ã®æ›´æ–°: TD_errorã‚’æ‰“ã¡æ¶ˆã™æ–¹å‘
        # TD_errorãŒæ­£ (å ±é…¬ãŒæœŸå¾…ä»¥ä¸Š) ã‹ã¤KãŒå°ã•ã„ -> theta_kappaã‚’å°ã•ãã™ã‚‹ (åŠªåŠ›ã‚’è¨±å®¹)
        # TD_errorãŒè²  (å ±é…¬ãŒæœŸå¾…ä»¥ä¸‹) ã‹ã¤KãŒå¤§ãã„ -> theta_kappaã‚’å¤§ããã™ã‚‹ (åŠªåŠ›ã‚’å«Œã†)
        delta_kappa = -update_magnitude * sign_TD * (K / K_max) * theta_kappa * 0.1

        # B. theta_gamma_K (KæŠ‘åˆ¶æ„Ÿå¿œåº¦) ã®æ›´æ–°:
        delta_gamma_K = update_magnitude * np.abs(TD_error) * (K / K_max) * 0.1

        # $\theta$ãƒ™ã‚¯ãƒˆãƒ«ã®æ›´æ–°
        theta['theta_kappa'] = np.clip(theta_kappa + delta_kappa, 0.001, cfg.THETA_MAX)
        theta['theta_gamma_K'] = np.clip(theta_gamma_K + delta_gamma_K, 0.001, cfg.THETA_MAX)

        # Delta_Theta_Normã®è¨ˆç®—ã®ãŸã‚ã«ã€ã“ã“ã§ã¯delta_kappaã®çµ¶å¯¾å€¤ã‚’è¿”ã™
        return np.abs(delta_kappa)


    def _apply_tdl_gradients(self, TD_error: float, history_item: dict):
        """
        ATDLLearnerã§è¨ˆç®—ã•ã‚ŒãŸTDèª¤å·®ã‚’ç”¨ã„ã¦ã€å®Ÿéš›ã«é‡ã¿ã‚’æ›´æ–°ã™ã‚‹ã€‚
        ã“ã“ã§ã¯W_Cã®ã¿ã‚’æ›´æ–°å¯¾è±¡ã¨ã™ã‚‹ï¼ˆç°¡ç•¥åŒ–ï¼‰ã€‚
        """
        cfg = self.config

        # ä¸å®‰ã«ã‚ˆã‚‹å­¦ç¿’æŠ‘åˆ¶ (ATDLLearnerå†…ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨)
        U_pz_mean = np.mean(history_item['U_pz'])
        theta_gamma_U = self.theta.get('theta_gamma_K', cfg.THETA_GAMMA_K_INIT)
        modulated_eta = cfg.ETA_TDL * np.exp(-theta_gamma_U * U_pz_mean)

        # ç°¡æ˜“BPTTã®å‹¾é…è¨ˆç®— (C(t-1)ã¨C(t)ã®å†å¸°ãƒ«ãƒ¼ãƒ—)
        C_prev = history_item['C']
        C_current_projection = np.tanh(history_item['Net_C'])

        # dW_C ã®ç°¡æ˜“å‹¾é…: TD_error * C_current_projection * C_prev.T
        delta_W_C = TD_error * np.outer(C_current_projection, C_prev)

        # W_C ã®æ›´æ–°
        W_C_next = self.W_C + modulated_eta * delta_W_C
        self.W_C = W_C_next

        return np.linalg.norm(delta_W_C) # ã‚¹ã‚­ãƒ«å­¦ç¿’ã®å¤‰å‹•ãƒãƒ«ãƒ 


    def step(self, user_input_text: str, external_reward: float):
        """
        Alice Architecture ã®å˜ä¸€ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ (æœ€çµ‚çµ±åˆç‰ˆ)ã€‚
        """
        self.t += 1
        self.external_reward = external_reward
        cfg = self.config

        # --- 1. ç’°å¢ƒå…¥åŠ› E_env ã®ç”Ÿæˆ ---
        E_token = self._generate_E_token(user_input_text)
        E_context = np.random.randn(cfg.N_ESELF) * 0.1
        E_scalar = np.array([external_reward, self.t % 100, self.t, 1 if np.random.rand() < 0.1 else 0]).reshape(-1, 1)
        E_env_t = np.concatenate([E_token, E_context.reshape(-1, 1), E_scalar])

        # --- 2. åˆæœŸè¡Œå‹• A(t) ã®ç”Ÿæˆ (tã®çŠ¶æ…‹C, Mã«åŸºã¥ã) ---
        Net_A_t = self.U_NLG_C @ self.C + self.U_NLG_M @ self.M
        A_t_initial = np.tanh(Net_A_t)[0] + self._add_noise(1)[0]
        A_t_initial = np.clip(A_t_initial, -1.0, 1.0)

        # --- 3. F_total (å…¨å†å¸°å†™åƒ) ã®å®Ÿè¡Œ: tã®çŠ¶æ…‹ã‚’å±¥æ­´ã«ä¿å­˜ã—ã€t+1ã®_nextçŠ¶æ…‹ã‚’è¨ˆç®— (CSCå‰ã®ãƒ™ãƒ¼ã‚¹) ---
        self._save_history(E_env_t, A_t_initial)
        self._update_layers(E_env_t, A_t_initial)

        # --- 4. æ„è­˜çš„å®‰å®šåŒ–æ¡ä»¶ (CSC) ã®å®Ÿè¡Œ: åŠªåŠ› K ã®è¨ˆæ¸¬ ---
        A_final_refined, K = self._run_csc_stabilization(E_env_t, A_t_initial)

        # --- 5. çŠ¶æ…‹ã®ã‚³ãƒŸãƒƒãƒˆ: å®‰å®šåŒ–ã•ã‚ŒãŸ_nextçŠ¶æ…‹ã‚’currentçŠ¶æ…‹ã« ---
        self._commit_state()

        # --- 6. å®‰å®šåŒ–ã•ã‚ŒãŸæœ€çµ‚V(t)ã®è¨ˆç®— (PTRE effort K ã‚’é©ç”¨) ---
        V_t, V_terms = self._calculate_V_from_state(K, state_prefix='')

        # --- 7. ã‚¹ã‚­ãƒ«å­¦ç¿’å‰‡ A-TDL ã®å®Ÿè¡Œ (TDèª¤å·®ã®è¨ˆç®—ã¨W_Cã®æ›´æ–°) ---
        TD_error = 0.0
        tdl_norm = 0.0
        # T_BPTTåˆ†ã®å±¥æ­´ãŒæºœã¾ã£ãŸã‚‰å­¦ç¿’é–‹å§‹
        if len(self.learner.history) >= cfg.T_BPTT and self.t > 1:
            # TDèª¤å·®ã®è¨ˆç®—: R(t-1) + gamma * V(t) - V(t-1)
            TD_error = self.learner.learn_step(V_t, self.V_prev, self.learner.history[-2], self.theta)

            # W_Cã®æ›´æ–°
            tdl_norm = self._apply_tdl_gradients(TD_error, self.learner.history[-2])

        self.V_prev = V_t # V(t)ã‚’æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®V(t+1)äºˆæ¸¬ã®ãŸã‚ã«ä¿å­˜

        # --- 8. äººæ ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\theta$ ã®é€²åŒ– (TDèª¤å·®ã®çµæœã‚’ç”¨ã„ã¦æ›´æ–°) ---
        # TDLãŒå®Ÿè¡Œã•ã‚ŒãŸå ´åˆã«ã®ã¿$\theta$ã‚’æ›´æ–°
        delta_theta_norm = 0.0
        if self.t > cfg.T_BPTT:
            delta_theta_norm = self._evolve_theta(TD_error, K)

        # --- 9. å‡ºåŠ› ---
        Var_ctrl = V_terms['Var_ctrl']
        tau_ctrl = 0.05
        is_stable = Var_ctrl <= tau_ctrl

        output = {
            'action': A_final_refined,
            'V_total': V_t,
            'V_base': V_terms['V_base'],
            'Effort_Cost': V_terms['Effort_Cost'],
            'K_effort': K, # æ–°ã—ã„å‡ºåŠ›: åŠªåŠ› K (åå¾©å›æ•°)
            'happiness_core': np.mean(self.H_pz),
            'uncertainty_core': np.mean(self.U_pz),
            'control_load': Var_ctrl,
            'is_stable': is_stable,
            'theta_snapshot': self.theta,
            'TD_error': TD_error,
            'Delta_Theta_Norm': delta_theta_norm, # äººæ ¼é€²åŒ–ã®å¤‰å‹•ãƒãƒ«ãƒ 
            'TDL_W_norm': tdl_norm # ã‚¹ã‚­ãƒ«å­¦ç¿’ã®å¤‰å‹•ãƒãƒ«ãƒ 
        }

        return output


# --- å®Ÿè¡Œä¾‹ ---

if __name__ == '__main__':
    print("--- Alice Architecture V3.0 - æœ€çµ‚çµ±åˆã‚³ã‚¢ (PTRE F_total å®Œå…¨çµ±åˆ) ---")
    alice = AliceArchitecture()
    print(f"çŸ¥æ€§ã‚³ã‚¢æ¬¡å…ƒæ•° (C): {alice.config.N_C}, BPTTçª“ (T_BPTT): {alice.config.T_BPTT}")
    print(f"åˆæœŸ $\\theta^\\kappa$ (åŠªåŠ›ã‚³ã‚¹ãƒˆæ„Ÿå¿œåº¦): {alice.theta['theta_kappa']:.6f}, $\\theta^\\beta$ (åŠªåŠ›ã‚³ã‚¹ãƒˆæŒ‡æ•°): {alice.theta['theta_beta']:.2f}")

    # çŠ¶æ…‹ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
    time_steps = 30 # T_BPTT=16ã‚’è¶…ãˆã¦å­¦ç¿’ãŒå§‹ã¾ã‚‹ã‚ˆã†ã«è¨­å®š
    # å ±é…¬ã¨å…¥åŠ›ã‚’è¨­å®šã—ã€ä¸å®‰å®šãªçŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    # å®‰å®š -> ä¸å®‰å®šï¼ˆä½å ±é…¬ï¼‰ -> å›å¾©ï¼ˆé«˜å ±é…¬ï¼‰ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
    rewards = [0.1] * 5 + [-0.9] * 5 + [0.8] * 10 + [0.1] * 10
    inputs = ["observe environment"] * time_steps

    print("\n--- Alice Architecture ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹ ---")

    initial_W_C_norm = np.linalg.norm(alice.W_C)
    initial_theta_kappa = alice.theta['theta_kappa']

    print(f"[t | R] V_total | V_base | Effort K | H | U | $\\theta^\\kappa$ | TD Error | TDL Norm")
    print("-" * 90)

    for i in range(time_steps):
        user_input = inputs[i]
        reward = rewards[i]

        result = alice.step(user_input, reward)

        # action_symbol = 'ğŸŸ¢' if result['action'] > 0 else ('ğŸ”´' if result['action'] < 0 else 'ğŸŸ¡')

        learning_status = f"{result['TDL_W_norm']:.2e}" if result['TDL_W_norm'] > 0 else "---"

        print(
            f"[{alice.t:02d} | {reward: 4.1f}] "
            f"V={result['V_total']: 6.2f} "
            f"({result['V_base']: 5.2f} - {result['Effort_Cost']: 4.2f}) | "
            f"K={result['K_effort']: 02d} | "
            f"H={result['happiness_core']: 4.2f} U={result['uncertainty_core']: 4.2f} | "
            f"$\\theta^\\kappa$={result['theta_snapshot']['theta_kappa']: 5.3f} | "
            f"TD={result['TD_error']: 5.2f} | "
            f"TDL={learning_status}"
        )

    final_W_C_norm = np.linalg.norm(alice.W_C)
    final_theta_kappa = alice.theta['theta_kappa']

    print("\n--- æœ€çµ‚å­¦ç¿’ã¨é€²åŒ–ã®ãƒã‚§ãƒƒã‚¯ ---")
    print(f"åˆæœŸ W_C ãƒãƒ«ãƒ : {initial_W_C_norm:.6f}")
    print(f"æœ€çµ‚ W_C ãƒãƒ«ãƒ : {final_W_C_norm:.6f} ({'ã‚¹ã‚­ãƒ«å­¦ç¿’ç™ºç”Ÿ' if abs(final_W_C_norm - initial_W_C_norm) > 1e-7 else 'å­¦ç¿’æœªç™ºç”Ÿ'})")
    print(f"åˆæœŸ $\\theta^\\kappa$: {initial_theta_kappa:.6f}")
    print(f"æœ€çµ‚ $\\theta^\\kappa$: {final_theta_kappa:.6f} ({'äººæ ¼é€²åŒ–ç™ºç”Ÿ' if abs(final_theta_kappa - initial_theta_kappa) > 1e-7 else 'é€²åŒ–æœªç™ºç”Ÿ'})")
    print(f"æœ€çµ‚ $\\theta^{\\gamma_K}$: {alice.theta['theta_gamma_K']:.6f}")
